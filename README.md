# Sign Language Detection using Machine Learning

Sign Language Detection is a **Machine Learning** based project designed to recognize and 
translate hand gestures representing sign language into readable text. 
This project aims to assist communication for people with hearing or speech impairments 
by using computer vision and deep learning techniques.

---

## üöÄ Features
- Real-time detection of hand gestures.
- Converts sign language to readable text.
- Uses Convolutional Neural Networks (CNNs) for image classification.
- Customizable and scalable model architecture.
- Can be integrated with voice or text-to-speech for complete communication aid.

## üõ†Ô∏è Technologies Used
- Programming Language: Python
- Libraries/Frameworks: OpenCV, TensorFlow / Keras, NumPy, Matplotlib
- IDE: Jupyter Notebook / VS Code
- Others: Scikit-learn, Pandas

## üß† Model Architecture
- Input Layer: Image (resized and normalized)
- Convolutional Layers
- Max Pooling Layers
- Flatten
- Dense Layers
- Output Layer: Softmax for classification of gestures (A-Z)

## ‚ñ∂Ô∏è How to Run
- Clone the repository
- Install the requirements (Never install these packages without activating "venv")
- Run the model after entering into yolov5 folder
- **python run.py**

